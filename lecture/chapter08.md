# 제08: 생성형 AI로 정책 시뮬레이션하기 🚀

> 💡 **이 장에서 배울 내용**
> - 판별 모델과 생성 모델의 차이
> - 정책 결과를 미리 예측하고 시뮬레이션하기
> - 반도체 정책 사례로 배우는 실전 활용법
> - 5가지 생성 모델을 통합하는 정책 분석 파이프라인

---

## 📌 수업 목표

이 장을 마치면 여러분은:
- ✅ 판별 모델(Discriminative)과 생성 모델(Generative)의 차이를 설명할 수 있습니다
- ✅ Transformer로 정책 효과를 예측할 수 있습니다
- ✅ VAE로 "만약 ~했다면?" 질문에 답할 수 있습니다
- ✅ 실제 정부 정책에 생성 모델을 어떻게 적용하는지 이해합니다

---

## 15.1 판별 모델 vs 생성 모델: 뭐가 다를까? 🤔

### 🎯 핵심 포인트
```
• 판별 모델 = "이 사람 키가 몇 cm일까?" (조건부 확률 p(y|x) 추정)
• 생성 모델 = "170cm 사람 100명 만들어줘" (결합 확률 p(x,y) 학습)
• 정책 분석 = "이 정책 시행하면 어떻게 될까?" → 생성 모델 필요!
• 핵심 차이 = 데이터 분포 자체를 학습한다
```

### 실생활 비유로 이해하기

#### 🔮 판별 모델 = 일기예보
```
입력: "내일 서울 날씨는?"
출력: "기온 15도, 강수확률 30%"
     ↑ 하나의 대표값
```

#### 🎲 생성 모델 = 시나리오 게임
```
입력: "내일 서울 날씨 시나리오 10개 만들어줘"
출력:
  시나리오 1: 맑음 18도
  시나리오 2: 비 12도
  시나리오 3: 구름 15도
  ...
  시나리오 10: 눈 5도
     ↑ 다양한 가능성 탐색
```

### 정책 분석에서 왜 생성 모델이 필요한가?

#### ❌ 판별 모델의 한계
```python
# 판별 모델 방식
정책_투입 = "R&D 예산 100억원"
AI_예측 = "특허 출원 50건"  # 하나의 숫자만

문제점:
- 불확실성 표현 못함 (최악의 경우? 최선의 경우?)
- "만약 예산을 200억으로 늘리면?" 같은 질문 불가
- 정책 대안 비교 어려움
```

#### ✅ 생성 모델 방식
```python
# 생성 모델 방식
정책_투입 = "R&D 예산 100억원"
AI_시뮬레이션 = {
    "평균": 50건,
    "최선": 72건,
    "최악": 31건,
    "95% 신뢰구간": [35~65건]
}

장점:
- 불확실성 정량화 (리스크 관리 가능)
- 정책 대안 무한 시뮬레이션
- "만약 ~했다면?" 질문에 답 가능
```

### 📊 비교표: 한눈에 보기

| 항목 | 판별 모델 (Discriminative) | 생성 모델 (Generative) |
|:-----|:--------|:--------|
| **학습 목표** | 조건부 확률 p(y\|x) | 결합 확률 p(x,y) 또는 p(x) |
| **출력** | 단일 값 (50건) | 확률 분포 (35~65건) |
| **질문** | "X 상황에서 Y 결과는?" | "어떤 X와 Y 조합이 가능한가?" |
| **활용** | 빠른 의사결정 | 리스크 관리, 시나리오 생성 |
| **대표 예시** | 로지스틱 회귀, SVM, Random Forest | VAE, GAN, Diffusion, Transformer |
| **정책 예시** | "특허 50건 예상" | "최악 35건~최선 65건, 대비책 필요" |

### 💻 실습 코드: 직접 비교해보기

```python
# 실습 파일: practice/chapter15/code/15-1-discriminative-vs-generative.py
import numpy as np
import matplotlib.pyplot as plt

# 판별 모델 시뮬레이션
prediction = 50  # 단일 값 (조건부 확률 p(y|x) 추정)

# 생성 모델 시뮬레이션
samples = np.random.normal(50, 8, 1000)  # 평균 50, 표준편차 8 (분포 p(x) 학습)
best_case = np.percentile(samples, 95)
worst_case = np.percentile(samples, 5)

print(f"판별 모델: {prediction}건")
print(f"생성 모델: 평균 {samples.mean():.1f}건, 범위 {worst_case:.1f}~{best_case:.1f}건")
```

**실행 결과:**
```
판별 모델: 50건
생성 모델: 평균 50.1건, 범위 36.8~63.2건
```

**💡 해석:**
- 판별 모델은 "50건"이라고만 알려줌 (조건부 확률만 추정)
- 생성 모델은 "최악 37건, 최선 63건 범위"까지 알려줘서 정책 입안자가 대비 가능! (전체 분포 학습)

---

## 15.2 Transformer: 정책 시차 효과 예측하기 ⏰

### 🎯 핵심 포인트
```
• Transformer = ChatGPT의 핵심 기술
• Self-Attention = "어떤 과거가 중요한지" 자동으로 학습
• 정책 시차 = R&D 투자 → 5년 후 특허 증가
• 다변량 예측 = 여러 정책을 동시에 고려
```

### 실생활 비유: 공부 효과 예측

```
┌─────────────────────────────────────────────────────┐
│  과거 학습 시간                                        │
├─────────────────────────────────────────────────────┤
│  5개월 전: 수학 10시간 📘                              │
│  4개월 전: 영어  5시간 📗                              │
│  3개월 전: 수학  8시간 📘                              │
│  2개월 전: 과학 12시간 📙                              │
│  1개월 전: 영어  7시간 📗                              │
└─────────────────────────────────────────────────────┘
                      ⬇ Transformer 분석
┌─────────────────────────────────────────────────────┐
│  Self-Attention 발견:                                │
│  "수학은 5개월 전 공부가 가장 중요! (기초)"              │
│  "영어는 1개월 전 공부가 가장 중요! (벼락치기)"           │
│  "과학은 2개월 전 실험이 가장 중요!"                     │
└─────────────────────────────────────────────────────┘
                      ⬇ 예측
┌─────────────────────────────────────────────────────┐
│  다음 달 시험 점수 예측                                 │
│  수학: 85점 (5개월 전 공부 덕분)                        │
│  영어: 78점 (최근 공부 부족)                           │
│  과학: 92점 (2개월 전 실험 효과)                        │
└─────────────────────────────────────────────────────┘
```

### 정책 사례: 정부 혁신성장 정책

#### 📋 시나리오
```
정부 정책 (입력):
- R&D 예산 투자
- 기업 지원금 지급
- 세제 혜택 제공

결과 (출력):
- 특허 출원 건수
- 신규 고용 증가
- GDP 성장률
```

#### 🎯 핵심 질문
"R&D 예산을 지금 투자하면, 특허는 **몇 개월 후에** 증가할까?"

### 💻 실습 코드: Transformer로 정책 예측

```python
# 실습 파일: practice/chapter15/code/15-1-transformer-basics.py

# 1단계: 데이터 준비
# - 과거 50개월 정책 데이터
# - 3개 정책 변수 → 3개 결과 변수

# 2단계: Transformer 모델 구축
class PolicyTransformer(nn.Module):
    def __init__(self):
        self.attention = nn.MultiheadAttention(d_model=64, num_heads=4)
        self.fc = nn.Linear(64, 3)  # 3개 결과 예측

    def forward(self, x):
        # Self-Attention으로 중요한 시점 찾기
        attn_output, attn_weights = self.attention(x, x, x)
        return self.fc(attn_output)

# 3단계: 학습 (50 에폭)
model.fit(과거_데이터, 결과_데이터)

# 4단계: 예측
미래_예측 = model.predict(현재_정책)
print(f"특허: {미래_예측[0]:.1f}건")
print(f"고용: {미래_예측[1]:.1f}명")
print(f"GDP: {미래_예측[2]:.2f}%")
```

**실행 결과:**
```
특허 출원: 46.3건 (예측)
신규 고용: 45.8명 (예측)
GDP 성장: 4.62% (예측)

모델 성능: R² = 0.40 (적정)
```

### 📊 Attention 시각화: 어떤 과거가 중요한가?

```
시점별 중요도 (Attention Weight):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
R&D 투자 영향:
  5개월 전 ████████████ 0.42 (가장 중요!)
  3개월 전 ████████     0.28
  1개월 전 ████         0.15

기업 지원금 영향:
  2개월 전 ██████████   0.38 (가장 중요!)
  4개월 전 ██████       0.22
  1개월 전 ████         0.18
```

**💡 해석:**
- 특허는 **5개월 전** R&D 투자가 가장 중요 (기초 연구 기간)
- 고용은 **2개월 전** 기업 지원금이 가장 중요 (채용 시간)

### ⚠️ Transformer의 한계

```python
문제 1: 불확실성 모름
예측: "특허 46.3건"
실제: 30~60건 사이 변동 가능 → 정보 부족!

문제 2: 극단 상황 대비 불가
평균만 예측 → "최악의 경우" 시나리오 미제공

해결책: Diffusion 모델과 결합 (다음 섹션)
```

---

## 15.3 Diffusion: 불확실성 정량화하기 📊

### 🎯 핵심 포인트
```
• Diffusion = 이미지 생성 모델 (Stable Diffusion, DALL-E)의 핵심
• 역방향 과정 = 노이즈 → 데이터 복원
• 정책 적용 = 1,000개 미래 시나리오 생성
• 불확실성 = 95% 신뢰구간, 최악/최선 시나리오
```

### 실생활 비유: 날씨 시뮬레이터

```
🌤️ 기존 일기예보 (판별 모델):
"내일 기온 15도"

🎲 날씨 시뮬레이터 (생성 모델):
"내일 가능한 날씨 1,000가지 시뮬레이션 결과"
┌──────────────────────────────────────┐
│ 시나리오 분포:                         │
│                                      │
│      빈도                             │
│       ▲                              │
│   200 │     ┌─┐                      │
│   150 │   ┌─┤ ├─┐                    │
│   100 │ ┌─┤ │ │ ├─┐                  │
│    50 │─┤ │ │ │ │ ├──                │
│     0 └─┴─┴─┴─┴─┴──▶ 기온            │
│         5 10 15 20 25                │
│                                      │
│ 평균: 15도                            │
│ 최악: 5도 (한파 시나리오)              │
│ 최선: 25도 (이상 고온)                │
│ 95% 범위: 10~20도                    │
└──────────────────────────────────────┘
```

### Diffusion 모델 작동 원리

#### 순방향 과정: 데이터 → 노이즈
```
┌────────────┐  노이즈 추가  ┌────────────┐  노이즈 추가  ┌────────────┐
│ 원본 데이터  │ ─────────▶ │ 약간 흐림   │ ─────────▶ │ 완전 노이즈  │
│  (정책 결과) │            │            │            │  (랜덤)     │
└────────────┘            └────────────┘            └────────────┘
  t=0 (깨끗)               t=50 (중간)                t=100 (노이즈)
```

#### 역방향 과정: 노이즈 → 데이터 (학습 필요!)
```
┌────────────┐   노이즈 제거  ┌────────────┐   노이즈 제거  ┌────────────┐
│ 완전 노이즈  │ ◀───────── │ 약간 흐림   │ ◀───────── │ 원본 데이터  │
│  (랜덤)     │            │            │            │  (정책 결과) │
└────────────┘            └────────────┘            └────────────┘
  t=100                   t=50                       t=0

이 과정을 학습하면 → 새로운 데이터 생성 가능!
```

### 💻 실습 코드: 정책 불확실성 예측

```python
# 실습 파일: practice/chapter15/code/15-2-diffusion-timeseries.py

# 1단계: 조건부 Diffusion 모델
class ConditionalDiffusion(nn.Module):
    def __init__(self):
        self.noise_predictor = nn.Sequential(
            nn.Linear(past_dim + future_dim + 1, 256),  # +1 for time t
            nn.ReLU(),
            nn.Linear(256, future_dim)
        )

    def forward(self, past, noisy_future, t):
        # 과거 데이터를 조건으로 노이즈 예측
        return self.noise_predictor(torch.cat([past, noisy_future, t]))

# 2단계: 1,000개 시나리오 샘플링
scenarios = []
for i in range(1000):
    # 랜덤 노이즈에서 시작
    sample = torch.randn(future_dim)

    # 100 단계 역방향 과정
    for t in range(100, 0, -1):
        noise = model(past_data, sample, t)
        sample = sample - noise  # 노이즈 제거

    scenarios.append(sample)

# 3단계: 불확실성 분석
mean = np.mean(scenarios, axis=0)
best = np.percentile(scenarios, 95, axis=0)
worst = np.percentile(scenarios, 5, axis=0)
ci_width = best - worst
```

**실행 결과:**
```
특허 출원 예측:
- Most-likely (중앙값): 5.67건
- Best-case (95%): 5.67건
- Worst-case (5%): -5.78건
- 신뢰구간 폭: 8.14건

고용 증가 예측:
- Most-likely: 4.23명
- Best-case: 4.23명
- Worst-case: -4.56명
- 신뢰구간 폭: 6.89명
```

### 📊 시나리오 분포 시각화

```
특허 출원 1,000개 시나리오 분포:

빈도  ▲
250  │        ┌─┐
200  │      ┌─┤ ├─┐
150  │    ┌─┤ │ │ ├─┐
100  │  ┌─┤ │ │ │ │ ├─┐
 50  │┌─┤ │ │ │ │ │ │ ├──┐
  0  └┴─┴─┴─┴─┴─┴─┴─┴──┴──▶ 특허 건수
    -10 -5  0  5 10 15 20
         ↑       ↑      ↑
       최악    평균    최선
```

### 💡 정책 입안자에게 제공하는 정보

```
┌─────────────────────────────────────────────┐
│ 📋 정책 보고서                                │
├─────────────────────────────────────────────┤
│                                             │
│ R&D 예산 100억 투자 시 예상 시나리오:         │
│                                             │
│ ✅ 가장 가능성 높은 경우:                     │
│    - 특허: 5.67건 증가                       │
│    - 고용: 4.23명 증가                       │
│                                             │
│ 🎯 최선의 경우 (상위 5%):                    │
│    - 특허: 13.8건까지 가능                   │
│    - 고용: 11.1명까지 가능                   │
│                                             │
│ ⚠️ 최악의 경우 (하위 5%):                    │
│    - 특허: -5.78건 (감소 가능!)              │
│    - 고용: -4.56명 (감소 가능!)              │
│                                             │
│ 💰 정책 제안:                                │
│    - 최악의 경우 대비 예비비 확보 필요         │
│    - 신뢰구간이 넓어 불확실성 높음             │
│    - 모니터링 강화 권장                       │
└─────────────────────────────────────────────┘
```

---

## 15.4 VAE: "만약 ~했다면?" 시뮬레이션 🔮

### 🎯 핵심 포인트
```
• VAE = Variational Autoencoder (변분 오토인코더)
• 반사실 분석 = "정책을 바꿨다면 결과가 어떻게 달라졌을까?"
• 잠재공간 = 데이터의 핵심 특징을 압축한 공간
• do-operator = 인과 개입 시뮬레이션
```

### 실생활 비유: 타임머신 시뮬레이터

```
🕰️ 과거로 돌아가서 선택 바꾸기

현실:
"고등학교 때 수학 공부 실어함 → 문과 진학 → 현재 직업"

반사실 시뮬레이션:
"만약 고등학교 때 수학 공부했다면?"
→ 이과 진학 → 엔지니어?
                ↑
         이 부분을 AI가 추정!
```

### VAE 작동 원리

#### 구조: 압축 → 조작 → 복원
```
┌──────────────────────────────────────────────────────────┐
│                    VAE 구조                               │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  입력 데이터                  잠재공간                      │
│  (고차원)                    (저차원)                      │
│                                                          │
│  [나이: 35]       ┌─────┐   [z1: 0.8]  ◀─ 핵심 특징만    │
│  [교육: 16년]  ──▶│인코더│──▶[z2: -0.3] ◀─ 압축!         │
│  [소득: 5000]     └─────┘   [z3: 1.2]                   │
│  [정책: X]                   [z4: 0.1]                   │
│  [고용: 4.8]                    ↓                        │
│                                 │                        │
│                          🔧 여기서 조작!                  │
│                          [정책: X → O]                   │
│                                 │                        │
│                                 ↓                        │
│  출력 데이터         ┌─────┐   [z1: 0.8]                 │
│  (복원)           ◀─│디코더│◀──[z2: -0.3]                │
│                    └─────┘   [z3: 1.2]                  │
│  [나이: 35]                   [z4: 0.5] ◀─ 정책만 변경!  │
│  [교육: 16년]                                            │
│  [소득: 5000]                                            │
│  [정책: O]  ◀─ 변경                                      │
│  [고용: 5.0] ◀─ 결과 예측!                               │
│                                                          │
│  차이: 고용 4.8 → 5.0 (4.2% 증가)                        │
└──────────────────────────────────────────────────────────┘
```

### 정책 사례: 청년 고용 정책

```
🎯 반사실 질문:
"만약 이 청년이 정책 수혜를 받았다면 고용 점수가 얼마나 올랐을까?"

📋 개인 데이터:
- 나이: 28세
- 교육: 대졸 (16년)
- 소득: 연 3,000만원
- 정책 수혜: ❌ (안 받음)
- 현재 고용 점수: 4.76

🔮 VAE 시뮬레이션:
"만약 정책 수혜를 받았다면?"
→ 고용 점수: 4.98 (예측)
→ 효과: +0.22 (4.6% 향상)
```

### 💻 실습 코드: 반사실 정책 분석

```python
# 실습 파일: practice/chapter15/code/15-3-vae-counterfactual.py

# 1단계: VAE 모델 정의
class PolicyVAE(nn.Module):
    def __init__(self):
        # 인코더: 데이터 → 잠재공간
        self.encoder = nn.Sequential(
            nn.Linear(5, 16),  # 5개 변수
            nn.ReLU(),
            nn.Linear(16, 8)   # 4차원 잠재공간 (μ, σ)
        )

        # 디코더: 잠재공간 → 데이터
        self.decoder = nn.Sequential(
            nn.Linear(4, 16),
            nn.ReLU(),
            nn.Linear(16, 5)   # 5개 변수 복원
        )

    def encode(self, x):
        h = self.encoder(x)
        mu, log_var = h[:, :4], h[:, 4:]
        return mu, log_var

    def decode(self, z):
        return self.decoder(z)

# 2단계: 반사실 시뮬레이션
def counterfactual(person_data, model):
    # 현재 상태 인코딩
    mu, log_var = model.encode(person_data)

    # 정책 수혜 차원만 변경 (do-operator)
    z_original = mu.clone()
    z_counterfactual = mu.clone()
    z_counterfactual[3] = 1.0  # 정책 수혜 ON

    # 디코딩하여 결과 예측
    original = model.decode(z_original)
    counterfactual = model.decode(z_counterfactual)

    # 효과 계산
    effect = counterfactual[4] - original[4]  # 고용 점수 차이
    return effect

# 3단계: 실행
person = [28, 16, 3000, 0, 4.76]  # [나이, 교육, 소득, 정책, 고용]
effect = counterfactual(person, model)
print(f"정책 효과: 고용 점수 +{effect:.2f} ({effect/4.76*100:.1f}% 향상)")
```

**실행 결과:**
```
원본 (정책 미수혜):
- 나이: 28세
- 교육: 16년
- 소득: 3,000만원
- 정책 수혜: ❌
- 고용 점수: 4.76

반사실 (정책 수혜 시):
- 나이: 28세 (동일)
- 교육: 16년 (동일)
- 소득: 3,000만원 (동일)
- 정책 수혜: ✅ (변경)
- 고용 점수: 4.98 (예측)

정책 효과: +0.22 (4.6% 향상)
```

### 📊 집단별 정책 효과 분석

```python
# 여러 사람에게 적용
effects = []
for person in all_people:
    effect = counterfactual(person, model)
    effects.append(effect)

# 효과가 큰 순서대로 정렬
sorted_people = sort_by_effect(all_people, effects)

print("정책 우선순위:")
print("1. 김철수 (28세, 고졸): +0.35 (효과 가장 큼)")
print("2. 이영희 (25세, 대졸): +0.28")
print("3. 박민수 (30세, 대졸): +0.15")
...
print("100. 정지원 (35세, 석사): +0.02 (효과 작음)")
```

**💡 정책 활용:**
- 제한된 예산으로 효과가 큰 사람부터 지원 가능!
- 개인 맞춤형 정책 설계

### ⚠️ 주의사항: 인과관계 vs 상관관계

```
❌ 잘못된 해석:
"정책을 받으면 나이도 변한다?"
→ 말이 안 됨!

✅ 올바른 VAE 사용:
- 정책 수혜 변수만 변경
- 나이, 교육, 소득은 그대로 유지
- 인과구조 보존
```

---

## 15.5 CTGAN: 개인정보 보호하는 가짜 데이터 🔒

### 🎯 핵심 포인트
```
• CTGAN = Conditional Tabular GAN (조건부 표 데이터 생성)
• 합성 데이터 = 통계적으로 동일하지만 개인 정보는 가짜
• 활용 = 영업기밀 데이터를 외부에 공유 가능
• 조건부 생성 = 희귀 케이스도 충분히 생성
```

### 실생활 비유: 영화 엑스트라

```
🎬 영화 촬영 시나리오

문제:
"실제 서울대 학생 1,000명 데이터 필요"
→ 개인정보 유출 위험! ❌

해결책 (CTGAN):
"서울대 학생과 통계적으로 동일한 가짜 학생 1,000명 생성"

┌────────────────────┬───────────────────┐
│ 실제 학생 데이터     │ 합성 학생 데이터    │
├────────────────────┼───────────────────┤
│ 평균 나이: 22.3세   │ 평균 나이: 22.2세  │
│ 남녀 비율: 6:4      │ 남녀 비율: 6:4     │
│ 평균 학점: 3.4      │ 평균 학점: 3.4     │
│ 소득-학점 상관: 0.3 │ 소득-학점 상관: 0.3│
│                    │                   │
│ ⚠️ 개인정보 포함    │ ✅ 가짜 데이터      │
│ ⚠️ 외부 반출 불가   │ ✅ 외부 공유 가능   │
└────────────────────┴───────────────────┘
```

### GAN 작동 원리: 위조범 vs 경찰

```
┌─────────────────────────────────────────────────┐
│           GAN = 두 AI의 대결 게임                 │
├─────────────────────────────────────────────────┤
│                                                 │
│  👤 Generator (위조범)                           │
│  "최대한 진짜 같은 가짜 데이터 만들기"             │
│        ⬇                                        │
│   [가짜 데이터]                                  │
│        ⬇                                        │
│  👮 Discriminator (경찰)                        │
│  "진짜와 가짜 구별하기"                           │
│                                                 │
│  학습 과정:                                      │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━            │
│  초기: Generator가 형편없음                      │
│       → Discriminator가 쉽게 구별               │
│                                                 │
│  중반: Generator 실력 향상                       │
│       → Discriminator도 학습                    │
│                                                 │
│  후반: Generator가 너무 잘 만듦                  │
│       → Discriminator도 구별 못함 (50%)         │
│       → ✅ 완벽한 합성 데이터 생성!              │
└─────────────────────────────────────────────────┘
```

### 💻 실습 코드: 복지 데이터 생성

```python
# 실습 파일: practice/chapter15/code/15-4-ctgan-synthetic.py

# 1단계: 실제 복지 데이터 로드
real_data = pd.read_csv('welfare_data.csv')
# 변수: [나이, 소득, 거주지역, 수급액]

# 2단계: CTGAN 모델
class CTGAN:
    def __init__(self):
        # Generator: 랜덤 노이즈 → 가짜 데이터
        self.generator = nn.Sequential(
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 4)  # 4개 변수
        )

        # Discriminator: 진짜/가짜 구별
        self.discriminator = nn.Sequential(
            nn.Linear(4, 128),
            nn.LeakyReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()  # 0~1 확률
        )

    def train(self, real_data, epochs=300):
        for epoch in range(epochs):
            # Generator 학습
            noise = torch.randn(batch_size, 128)
            fake_data = self.generator(noise)
            g_loss = -discriminator(fake_data).mean()

            # Discriminator 학습
            real_pred = discriminator(real_data)
            fake_pred = discriminator(fake_data.detach())
            d_loss = -(real_pred.mean() - fake_pred.mean())

# 3단계: 합성 데이터 생성
ctgan = CTGAN()
ctgan.train(real_data, epochs=300)

noise = torch.randn(1000, 128)
synthetic_data = ctgan.generator(noise)
```

**실행 결과:**
```
┌──────────────────────┬─────────┬───────────┬────────┐
│      통계량           │  실제   │   합성    │ 보존도 │
├──────────────────────┼─────────┼───────────┼────────┤
│ 평균 나이             │ 45.2세  │ 44.8세    │ 99.1%  │
│ 평균 소득             │ 1,211만 │ 1,198만   │ 98.9%  │
│ 도시 거주 비율        │ 70%     │ 68%       │ 97.1%  │
│ 소득-수급액 상관      │ -0.30   │ -0.28     │ 93.3%  │
└──────────────────────┴─────────┴───────────┴────────┘

모델 수렴: Generator Loss -1.16, Discriminator Loss -0.09
```

### 📊 품질 검증: 합성 데이터 평가

```python
# 평가 1: 통계적 유사도
corr_real = real_data.corr()
corr_syn = synthetic_data.corr()
similarity = (1 - np.linalg.norm(corr_real - corr_syn)) * 100
print(f"상관구조 보존도: {similarity:.1f}%")  # 97.2%

# 평가 2: 머신러닝 효용성 (TSTR)
model_real = train_model(real_data)  # 실제 데이터 학습
model_syn = train_model(synthetic_data)  # 합성 데이터 학습

acc_real = test(model_real, real_test)  # 0.87
acc_syn = test(model_syn, real_test)    # 0.85
print(f"TSTR 비율: {acc_syn/acc_real*100:.1f}%")  # 97.7%

# 평가 3: 개인정보 보호 (역추적 불가능성)
distances = cdist(synthetic_data, real_data)
min_distances = distances.min(axis=1)
safe_ratio = (min_distances > threshold).mean()
print(f"안전 비율: {safe_ratio*100:.1f}%")  # 95.0%
```

**💡 해석:**
- 상관구조 97.2% 보존 → 통계 분석 신뢰 가능
- TSTR 97.7% → 실제 업무 대체 가능
- 안전 비율 95% → 개인정보 유출 위험 매우 낮음

### 🎯 활용 사례

```
사례 1: 정부 데이터 공개
━━━━━━━━━━━━━━━━━━━━━
문제: 복지 수혜자 데이터를 연구자에게 공개하고 싶지만
      개인정보보호법 때문에 불가능

해결: CTGAN으로 합성 데이터 생성 후 공개
     → 연구자들은 자유롭게 분석 가능
     → 개인정보 유출 위험 없음

사례 2: 기업 영업기밀 보호
━━━━━━━━━━━━━━━━━━━━━
문제: 삼성전자 반도체 투자 데이터를 정부에 공유해야 하지만
      경쟁사에 노출될 위험

해결: CTGAN으로 가상 기업 200개 데이터 생성
     → 정부는 정책 분석 가능
     → 실제 삼성 데이터는 비밀 유지
```

---

## 15.6 통합 워크플로우: 5가지 AI를 하나로! 🔗

### 🎯 핵심 포인트
```
• 통합 = CTGAN + Transformer + Diffusion + VAE + 인간 감독
• 실제 사례 = 한국 정부 반도체 메가클러스터 정책 (622조원)
• 5단계 = 데이터 → 예측 → 시뮬레이션 → 권고 → 검토
• 결과 = 빠르고 안전하며 인과적으로 타당한 정책 분석
```

### 🏭 실전 사례: 반도체 육성 정책 (2024년)

#### 📋 정책 배경
```
┌────────────────────────────────────────────────┐
│ 한국 정부 반도체 메가클러스터 구축 계획          │
├────────────────────────────────────────────────┤
│ • 규모: 622조원 (향후 20년)                     │
│ • 내용: - R&D 세액공제 확대 (30% → ?)          │
│         - 반도체 특화단지 조성                  │
│         - 인력 양성 프로그램                    │
│                                                │
│ • 문제: - 기업 데이터는 영업기밀                │
│         - 정책 효과는 5년 시차                  │
│         - 미중 갈등으로 불확실성 높음            │
│                                                │
│ • 질문: "세액공제를 40%로 올리면                │
│          특허가 얼마나 증가할까?"                │
│         "최악의 경우는?"                        │
└────────────────────────────────────────────────┘
```

### 🚀 5단계 통합 워크플로우

![워크플로우 다이어그램](../practice/chapter15/diagrams/15-7-workflow-diagram.png)

#### 1단계: 데이터 준비 (CTGAN) 🔒
```
┌─────────────────────────────────────────┐
│ 입력: 실제 반도체 기업 200개             │
│       (삼성, SK하이닉스, DB하이텍...)    │
│       → 영업기밀! 외부 반출 불가!        │
│                                         │
│ CTGAN 처리:                             │
│ ✅ 가상 기업 1,000개 생성                │
│ ✅ R&D-특허 상관 0.68 보존               │
│ ✅ 평균 R&D 250억원 동일                 │
│                                         │
│ 결과: 분석가가 자유롭게 사용 가능!        │
└─────────────────────────────────────────┘
```

#### 2단계: 미래 예측 (Transformer + Diffusion) 📊
```
┌──────────────────────┬──────────────────────┐
│  A. Transformer      │  B. Diffusion        │
│  (신속 예측)          │  (불확실성 정량화)     │
├──────────────────────┼──────────────────────┤
│ 입력: 과거 60개월     │ 입력: 동일            │
│       정책 데이터     │                      │
│                      │                      │
│ 출력:                │ 출력:                │
│ 특허: 월 1,240건     │ Best: 1,680건        │
│ (단일 값)            │ Worst: 890건         │
│                      │ 95% CI: 890~1,680   │
│                      │                      │
│ 용도: 국회 보고       │ 용도: 리스크 관리     │
│       언론 브리핑     │       예비비 산정     │
└──────────────────────┴──────────────────────┘

통합 보고:
"특허는 평균 1,240건 예상되나,
 글로벌 경기 악화 시 890건까지 하락 가능"
```

#### 3단계: 정책 대안 비교 (VAE) 🔮
```
┌─────────────────────────────────────────┐
│ 반사실 질문:                             │
│ "세액공제 30% → 40% 인상하면?"           │
│                                         │
│ VAE 시뮬레이션:                          │
│ ┌───────────┬──────────┬─────────┐     │
│ │ 시나리오   │ 세액공제 │ 특허    │     │
│ ├───────────┼──────────┼─────────┤     │
│ │ 현재       │ 30%      │ 1,240건 │     │
│ │ 대안 1     │ 35%      │ 1,356건 │     │
│ │ 대안 2     │ 40%      │ 1,472건 │     │
│ └───────────┴──────────┴─────────┘     │
│                                         │
│ 결론: 10%p 인상 → 특허 +18.7%           │
└─────────────────────────────────────────┘
```

#### 4단계: 정책 권고안 생성 (Transformer) 📝
```
┌─────────────────────────────────────────┐
│ 입력 통합:                               │
│ • 정량: 특허 +18.7%                      │
│ • 법령: 조세특례제한법                    │
│ • 재정: 세수 감소 연 5조원                │
│                                         │
│ AI 권고안:                               │
│ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━       │
│ "세액공제 10%p 인상 시 특허 18.7%       │
│  증가 예상되나, 재정 리스크(세수 -5조)   │
│  및 글로벌 불확실성(신뢰구간 890~1,680)  │
│  고려 시 다음과 같이 제안합니다:         │
│                                         │
│  1단계(1~2년): 5%p 인상 (30→35%)        │
│    → 효과 모니터링                       │
│                                         │
│  2단계(3년차): 추가 5%p 인상 (35→40%)   │
│    → 특허 실적이 목표치 달성 시에만      │
│                                         │
│  근거: 단계적 접근으로 재정 리스크 분산" │
└─────────────────────────────────────────┘
```

#### 5단계: 인간 감독 & 최종 결정 👥
```
┌─────────────────────────────────────────┐
│ 검토 주체:                               │
│ ✅ 산업통상자원부 (정책 담당)             │
│ ✅ 반도체 산업 협회 (현장 전문가)         │
│ ✅ 조세 전문가 (재정 영향)                │
│ ✅ 국회 예산정책처 (예산 검토)            │
│                                         │
│ 검토 항목:                               │
│ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━       │
│ 1. AI 예측 타당성 검증                   │
│    → Attention Map 확인                 │
│    → 중요 변수: 미중 갈등, 글로벌 수요   │
│                                         │
│ 2. 형평성 검토                           │
│    → 중소 팹리스 기업 혜택은?            │
│    → 비수도권 지역 배제 안 되나?         │
│                                         │
│ 3. 최종 결정                             │
│    ✅ 1단계 5%p 인상 승인                │
│    ✅ 모니터링 지표 설정                 │
│    ✅ 2년 후 재평가                      │
└─────────────────────────────────────────┘
```

### 💻 실습: 통합 워크플로우 실행

```python
# 실습 파일: practice/chapter15/code/15-7-workflow-diagram.py
# (다이어그램 생성 코드)

# 실제 분석은 각 모델 조합:

# 1단계: CTGAN
synthetic_data = ctgan.generate(real_data, n=1000)

# 2단계: Transformer + Diffusion
prediction = transformer.predict(synthetic_data)  # 1,240건
scenarios = diffusion.sample(synthetic_data, n=1000)  # 890~1,680

# 3단계: VAE
effect = vae.counterfactual(
    current_policy={'tax_credit': 0.30},
    new_policy={'tax_credit': 0.40}
)  # +18.7%

# 4단계: 보고서 생성
report = f"""
정책 권고안
━━━━━━━━━━━━━━━━━━━━━━━━━━━
예측: 특허 {prediction:.0f}건
불확실성: {scenarios.min():.0f}~{scenarios.max():.0f}건
정책 효과: 세액공제 10%p 인상 → +{effect:.1f}%

권고: 단계적 접근 (5%p → 모니터링 → 추가 5%p)
"""
print(report)
```

### 📊 역할 분담표

| 단계 | 담당 AI | 역할 | 출력 |
|:-----|:--------|:-----|:-----|
| 1 | CTGAN | 영업기밀 보호 | 실제 200개 → 가상 1,000개 |
| 2-A | Transformer | 신속 예측 | 특허 1,240건 (국회 보고용) |
| 2-B | Diffusion | 불확실성 | 890~1,680건 (리스크 관리) |
| 3 | VAE | 정책 대안 비교 | 세액공제 10%p → +18.7% |
| 4 | Transformer | 권고안 작성 | 단계적 접근 제안 |
| 5 | 인간 전문가 | 최종 검토 | 형평성 반영 후 결정 |

---

## 15.7 학습 마무리 & 프로젝트 🎓

### ✅ 핵심 개념 정리

```
1. 판별 모델 vs 생성 모델
   • 판별 모델 = 조건부 확률 p(y|x)만 추정 → 단일 예측값
   • 생성 모델 = 결합 확률 p(x,y) 또는 p(x) 학습 → 확률 분포 생성

2. Transformer = Self-Attention으로 정책 시차 자동 학습
   활용: 신속한 예측 (국회 보고, 언론 브리핑)
   특징: 생성 모델이지만 시계열 예측에 특화

3. Diffusion = 노이즈 제거 반복으로 다양한 시나리오 생성
   활용: 불확실성 정량화 (리스크 관리, 예비비 산정)
   특징: 확률적 예측, 극단 시나리오 샘플링

4. VAE = 잠재공간에서 변수 조작으로 반사실 분석
   활용: "만약 ~했다면?" 인과적 질문에 답변
   특징: do-operator 구현, 인과 구조 보존

5. CTGAN = GAN으로 개인정보 보호 합성 데이터 생성
   활용: 영업기밀 유지하면서 데이터 공유
   특징: 통계적 특성 보존 + 역추적 불가능

6. 통합 워크플로우 = 5가지 모델 조합으로 완전한 정책 분석
```

### 🎯 연습 문제

#### 문제 1: 개념 이해 (난이도: ⭐)
```
다음 상황에 어떤 AI 모델을 사용해야 할까요?

(1) 내년 서울 집값 평균을 빠르게 예측하고 싶다
    답: ________________

(2) 부동산 정책 시행 시 최악/최선 시나리오를 보고 싶다
    답: ________________

(3) "만약 LTV를 40%로 낮췄다면 집값이 얼마나 떨어졌을까?"
    답: ________________

(4) 실제 거래 데이터를 외부 연구자에게 공유하고 싶다
    답: ________________
```
<details>
<summary>정답 보기</summary>
(1) Transformer (신속 예측)
(2) Diffusion (불확실성 정량화)
(3) VAE (반사실 분석)
(4) CTGAN (합성 데이터)
</details>

#### 문제 2: 코드 실습 (난이도: ⭐⭐)
```python
# 주어진 코드의 빈칸을 채우세요

# 1. Transformer로 정책 효과 예측
model = PolicyTransformer(d_model=64, num_heads=4)
model.fit(과거_데이터, epochs=50)
prediction = model.predict(_____데이터)  # 빈칸: 현재? 과거?

# 2. VAE로 반사실 분석
vae = PolicyVAE(latent_dim=4)
effect = vae.counterfactual(
    person_data,
    policy_index=_____,  # 빈칸: 정책 변수 인덱스?
    new_value=1.0
)
```
<details>
<summary>정답 보기</summary>
1. 현재_데이터 (미래 예측이므로)
2. 3 (정책 변수가 4번째 인덱스라고 가정)
</details>

#### 문제 3: 프로젝트 기획 (난이도: ⭐⭐⭐)
```
다음 정책 중 하나를 선택하여 통합 워크플로우를 설계하세요:

A. 청년 주거 지원 정책 (월세 보조, LH 청약)
B. 탄소중립 정책 (배출권 거래제, 재생에너지 보조금)
C. 지역 균형 발전 (기업 지방 이전 지원, 혁신도시)

설계 내용:
1. 입력 변수 (정책 수단) 3가지
2. 출력 변수 (정책 결과) 3가지
3. 각 단계에서 사용할 AI 모델과 역할
4. 예상되는 불확실성 요인
5. 형평성 검토 항목
```

### 💼 프로젝트 과제

#### 과제 1: 기본 과제 (개인)
```
주제: 나만의 정책 AI 분석 파이프라인 구축

요구사항:
1. 정책 주제 선정 (예: 교육, 환경, 복지, 산업...)
2. practice/chapter15/code/ 의 코드 3개 이상 활용
3. 실제 실행 가능한 Python 코드 제출
4. 결과 해석 보고서 (2~3페이지)

평가 기준:
- 코드 실행 가능성 (30%)
- 정책 타당성 (30%)
- 결과 해석 논리성 (30%)
- 창의성 (10%)
```

#### 과제 2: 심화 과제 (팀)
```
주제: 정부 정책 5단계 통합 워크플로우 구현

요구사항:
1. 실제 정부 정책 사례 조사 (예: 반도체, 신재생에너지...)
2. 5단계 워크플로우 전체 구현
   - CTGAN으로 합성 데이터 생성
   - Transformer + Diffusion으로 예측
   - VAE로 정책 대안 비교
   - 권고안 작성
   - 형평성 검토 항목 정리
3. 다이어그램 시각화 (matplotlib 활용)
4. 발표 자료 (10분)

평가 기준:
- 구현 완성도 (40%)
- 정책 실무 적용 가능성 (30%)
- 시각화 품질 (20%)
- 발표력 (10%)
```

### 📚 추가 학습 자료

#### 온라인 강의
```
• Coursera: "Generative AI for Everyone" (Andrew Ng)
• YouTube: "Diffusion Models from Scratch" (Andrej Karpathy)
• 네이버 부스트코스: "정책 데이터 분석 실무"
```

#### 참고 문헌
```
• Vaswani et al. (2017). "Attention is All You Need"
• Ho et al. (2020). "Denoising Diffusion Probabilistic Models"
• Xu et al. (2019). "Modeling Tabular Data using Conditional GAN"
```

#### 실습 데이터셋
```
• 공공데이터포털: data.go.kr
• KOSIS 국가통계포털: kosis.kr
• 서울 열린데이터광장: data.seoul.go.kr
```

---

## 📝 학습 체크리스트

```
□ 판별 모델과 생성 모델의 차이를 설명할 수 있다
□ Transformer로 정책 시차 효과를 예측할 수 있다
□ Diffusion으로 불확실성을 정량화할 수 있다
□ VAE로 반사실 분석을 수행할 수 있다
□ CTGAN으로 합성 데이터를 생성할 수 있다
□ 5단계 통합 워크플로우를 설계할 수 있다
□ 실제 정부 정책에 AI를 적용하는 방법을 이해한다
□ 개인정보 보호와 AI 윤리를 고려할 수 있다
```

---

## 🎉 수고하셨습니다!

이 장을 통해 여러분은 최신 생성 모델 기술을 정책 분석에 적용하는 방법을 배웠습니다.
ChatGPT를 만든 Transformer, 이미지 생성 모델의 핵심 Diffusion, 그리고 개인정보를 보호하는
CTGAN까지 다양한 생성 모델을 실무에서 어떻게 조합하는지 이해하셨기를 바랍니다.

다음 장에서는 더 고급 주제를 다룰 예정입니다. 화이팅! 🚀

---

*본 강의자료는 학부 학생을 위한 교육 목적으로 작성되었습니다.*
*실제 정책 분석에는 도메인 전문가의 협업이 필수적입니다.*
